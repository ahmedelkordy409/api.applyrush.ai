# LangGraph Integration Setup Guide

## üéâ What's Been Implemented

Your JobHire.AI backend now has full LangGraph integration with:

### ‚úÖ Core Components
- **LangGraph Workflows**: End-to-end job application processing
- **Database Integration**: PostgreSQL/Supabase compatible 
- **AI Service Layer**: Enhanced with workflow orchestration
- **REST API Endpoints**: `/api/v1/workflows/*` endpoints
- **Monitoring & Analytics**: Workflow performance tracking

### ‚úÖ Key Workflows
1. **Job Application Workflow**: Complete automated application process
2. **Job Analysis Workflow**: AI-powered job matching
3. **User Optimization Workflow**: Profile improvement suggestions

## üîß Database Setup Required

You need to connect to your real Supabase database:

### 1. Update your `.env` file:
```bash
# Your existing Supabase connection
DATABASE_URL=postgresql://[user]:[password]@[host]:[port]/[database]
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key

# AI Services (if not already set)
OPENAI_API_KEY=your-openai-key
REPLICATE_API_TOKEN=your-replicate-token
```

### 2. Run the database migration:
```bash
# Navigate to your project directory
cd /home/ahmed-elkordy/researchs/applyrush.ai/jobhire-ai-backend

# Run the SQL migration script
psql $DATABASE_URL -f app/workflows/migrations/001_create_workflow_tables.sql
```

Or connect to your Supabase dashboard and run the SQL from:
`app/workflows/migrations/001_create_workflow_tables.sql`

### 3. Test the connection:
```bash
python -c "
import asyncio
from app.core.database import database

async def test_db():
    await database.connect()
    result = await database.fetch_one('SELECT 1 as test')
    print(f'Database connected: {result}')
    await database.disconnect()

asyncio.run(test_db())
"
```

## üöÄ Running the Enhanced System

### 1. Start the server:
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 2. Test the new endpoints:
- Visit: http://localhost:8000/docs
- New workflow endpoints under `/workflows/`

### 3. Key API Endpoints:

#### Job Application Processing
```bash
POST /api/v1/workflows/job-application
{
  "user_id": "user123",
  "job_data": {...},
  "user_profile": {...},
  "user_tier": "free"
}
```

#### Batch Job Processing
```bash
POST /api/v1/workflows/batch-job-applications
{
  "user_id": "user123", 
  "jobs": [job1, job2, ...],
  "user_profile": {...},
  "max_concurrent": 5
}
```

#### Job Match Analysis
```bash
POST /api/v1/workflows/job-match-analysis
{
  "job_data": {...},
  "user_profile": {...}
}
```

#### User Analytics
```bash
GET /api/v1/workflows/user/{user_id}/analytics?days=30
```

## üìä New Database Tables

The migration creates these tables:
- `workflow_executions`: Stores workflow run data
- `job_applications`: Tracks application submissions  
- `workflow_analytics`: Performance metrics

## üéØ Benefits You Now Have

### 1. **Sophisticated Job Processing**
- Multi-step AI decision making
- Company research integration
- Resume optimization
- Cover letter generation
- Automated follow-up scheduling

### 2. **Scalable Architecture**
- Concurrent job processing
- Workflow state management
- Error handling and recovery
- Performance monitoring

### 3. **Enhanced AI Capabilities**
- Context-aware AI calls
- Cost optimization
- Model selection based on user tier
- Response quality validation

### 4. **Rich Analytics**
- User workflow history
- Success rate tracking
- AI cost monitoring
- Performance metrics

## üîç Testing Your Setup

### 1. Run the test suite:
```bash
python test_simple.py
```

### 2. Test a simple workflow:
```bash
curl -X POST "http://localhost:8000/api/v1/workflows/job-match-analysis" \
  -H "Content-Type: application/json" \
  -d '{
    "job_data": {
      "external_id": "test123",
      "title": "Software Engineer", 
      "description": "Python developer needed",
      "required_skills": ["Python", "FastAPI"]
    },
    "user_profile": {
      "skills": ["Python", "JavaScript"],
      "experience_years": 3
    }
  }'
```

## üîÑ Integration with Existing System

Your existing endpoints continue to work, but now you can:

1. **Migrate gradually**: Use new workflows for new features
2. **Enhance existing**: Replace simple AI calls with workflows
3. **Add intelligence**: Use workflows for complex decision making

## üö® Important Notes

1. **API Keys**: Set OpenAI API key for full functionality
2. **Database**: Run migrations before first use
3. **Monitoring**: Workflows track costs and performance
4. **Scaling**: Adjust `max_concurrent` based on your needs

## üìà Next Steps

1. **Connect your database** (priority #1)
2. **Test the workflows** with real data
3. **Integrate with your frontend** 
4. **Monitor performance** and costs
5. **Customize workflows** for your specific needs

Your JobHire.AI system is now powered by LangGraph for sophisticated, scalable AI workflows! üéâ